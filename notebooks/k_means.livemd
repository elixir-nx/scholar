# K-means tutorial

```elixir
Mix.install(
  [
    {:stb_image, "~> 0.5.2"},
    {:kino, github: "livebook-dev/kino", override: true},
    {:nx, github: "elixir-nx/nx", sparse: "nx", override: true},
    {:exla, "~> 0.3"},
    {:explorer, "~> 0.2.0"},
    {:scholar, github: "elixir-nx/scholar"},
    {:vega_lite, "~> 0.1.6"},
    {:jason, "~> 1.2"},
    {:kino_vega_lite, "~> 0.1.3"},
    {:scidata, "~> 0.1.9"},
    {:req, "~> 0.2.0"}
  ],
  config: [
    nx: [default_defn_options: [compiler: EXLA]]
  ]
)
```

## General Info

The main purpose of this livebook is to introduce the KMeans clustering algorithm. We will explore KMeans in three different use cases.

```elixir
import Nx.Defn
alias VegaLite, as: Vl
```

## Iris Dataset

The first example we will focus on is the **Iris Dataset**. It is one of the most renowned datasets. It consists of 150 records describing three iris species: *Iris Setosa*, *Iris Virginica*, and *Iris Versicolor*. Our task will be to predict the species of given flowers.

<!-- livebook:{"break_markdown":true} -->

Let's define module `Datasets` which will help us load data from Explorer Dataframe into the Nx tensor.

```elixir
defmodule Datasets do
  def df_to_matrix(df) do
    df
    |> Explorer.DataFrame.names()
    |> Enum.map(&(Explorer.Series.to_tensor(df[&1]) |> Nx.new_axis(-1)))
    |> Nx.concatenate(axis: 1)
  end

  def df_to_vector(df) do
    case Explorer.DataFrame.names(df) do
      [name] -> Explorer.Series.to_tensor(df[name])
      _several -> df |> df_to_matrix() |> Nx.argmax(axis: 1)
    end
  end

  defn sort_clusters(model) do
    order = Nx.argsort(model.clusters[[0..-1//1, 0]])
    labels_maping = Nx.argsort(order)

    %{
      model
      | labels: Nx.take(labels_maping, model.labels),
        clusters: Nx.take(model.clusters, order)
    }
  end
end
```

Firstly, we load the data, then we split it into Training Data (df) and Target (y) and cast it into Nx tensors.

```elixir
df_raw = Explorer.Datasets.iris()
y = Explorer.DataFrame.select(df_raw, ["species"]) |> Explorer.DataFrame.dummies(["species"])
y = Datasets.df_to_vector(y)
df = Explorer.DataFrame.select(df_raw, ["species"], :drop)
df = Datasets.df_to_matrix(df)
```

### Exploratory Data Analysis

<!-- livebook:{"break_markdown":true} -->

Important part of Data Science workflow is something called **Exploratory Data Analysis**. The EDA helps us understand the data in a better way and suggests some efficient strategies to solve problems. There is no one specific course of action which defines good EDA. It should contain tabular summaries and plots showing relations between features.

<!-- livebook:{"break_markdown":true} -->

We start our EDA by finding the mean values of each feature by specie.

```elixir
grouped_data = Explorer.DataFrame.group_by(df_raw, ["species"])

grouped_data
|> Explorer.DataFrame.summarise(
  petal_length: [:mean],
  petal_width: [:mean],
  sepal_width: [:mean],
  sepal_length: [:mean]
)
```

We see that `petal_length` and `petal_width` are the most distinguishing features. Explore them a little bit more.

```elixir
Vl.new(title: [text: "Histograms of petal_length column by specie", offset: 25])
|> Vl.data_from_values(df_raw)
|> Vl.facet(
  [field: "species"],
  Vl.new(width: 200, height: 200)
  |> Vl.mark(:bar)
  |> Vl.encode_field(:x, "petal_length", type: :quantitative, bin: true)
  |> Vl.encode_field(:y, "Frequency", aggregate: "count", scale: [domain: [0, 55]])
)
```

```elixir
Vl.new(
  width: 300,
  height: 300,
  title: [
    text: "Scatterplot of data samples pojected on plane petal_width x petal_length",
    offset: 25
  ]
)
|> Vl.data_from_values(df_raw)
|> Vl.mark(:circle)
|> Vl.encode_field(:x, "petal_length", type: :quantitative)
|> Vl.encode_field(:y, "petal_width", type: :quantitative)
|> Vl.encode_field(:color, "species")
```

```elixir
Vl.new(
  title: [
    text: "Scatterplot of data samples pojected on plane petal_width x petal_length by specie",
    offset: 25
  ]
)
|> Vl.data_from_values(df_raw)
|> Vl.facet(
  [field: "species"],
  Vl.new(width: 200, height: 200)
  |> Vl.mark(:point)
  |> Vl.encode_field(:x, "petal_length", type: :quantitative)
  |> Vl.encode_field(:y, "petal_width", type: :quantitative)
)
```

Now we have a better understanding of data. Iris species have different petal widths and petal lengths. Iris *Setosa* has the smallest petal *Versicolor* is medium size and *Virginica* has the biggest petal. We can make sure even further that our analysis is correct and plot the so-called **Elbow plot**. The Elbow plot is a plot which presents Inertia vs the number of clusters. If there is a characteristic elbow on, then we have a strong suggestion about the right number of clusters. Let's train KMeans models for a different number of clusters from range 1 to 11.

```elixir
models = for i <- 1..11, do: Scholar.Cluster.KMeans.fit(df, num_clusters: i)
inertia_of_models = for model <- models, do: Nx.to_number(model.inertia)
```

```elixir
data = [num_clusters: 1..11, inertia: inertia_of_models]

Vl.new(width: 600, height: 300, title: "Elbow Plot")
|> Vl.data_from_values(data)
|> Vl.mark(:line)
|> Vl.encode_field(:x, "num_clusters",
  title: "Number of Clusters",
  type: :ordinal,
  axis: [label_angle: 0]
)
|> Vl.encode_field(:y, "inertia", title: "Inertia", type: :quantitative)
```

As you can see, we have the elbow when the number of clusters equals three. So this value of the parameter seems to be the best.

```elixir
best_model = Enum.at(models, 2)
best_model = Datasets.sort_clusters(best_model)
accuracy = Scholar.Metrics.accuracy(best_model.labels, y)
```

Accuracy is nearly 90%, that pretty decent! Let's look at our results plotted on one of the previous plots.

```elixir
coords = best_model.clusters[[0..-1//1, 2..-1//1]] |> Nx.to_flat_list()

coords = [
  x_coords: for(i <- [0, 2, 4], do: Enum.at(coords, i)),
  y_coords: for(i <- [1, 3, 5], do: Enum.at(coords, i))
]

Vl.new(
  width: 300,
  height: 300,
  title: [
    text:
      "Scatterplot of data samples pojected on plane petal_width x petal_length with calculated centroids",
    offset: 25
  ]
)
|> Vl.layers([
  Vl.new()
  |> Vl.data_from_values(df_raw)
  |> Vl.mark(:circle)
  |> Vl.encode_field(:x, "petal_length", type: :quantitative)
  |> Vl.encode_field(:y, "petal_width", type: :quantitative)
  |> Vl.encode_field(:color, "species"),
  Vl.new()
  |> Vl.data_from_values(coords)
  |> Vl.mark(:circle, color: :green, size: 100)
  |> Vl.encode_field(:x, "x_coords", type: :quantitative)
  |> Vl.encode_field(:y, "y_coords", type: :quantitative)
])
```

As we expect ðŸ˜Ž

## Clustering of pixels' colors

The other interesting use case of KMeans clustering is pixel clustering. This technique replaces all pixels with similar colors (similar in terms of euclidean distance between RGB) with a centroid related to them.

<!-- livebook:{"break_markdown":true} -->

Let us start with loading the referral image.

```elixir
url =
  "https://pix4free.org/assets/library/2021-01-12/originals/san_francisco_california_golden_gate_bridge_water.jpg"

%{body: raw_image} = Req.get!(url)
image = StbImage.read_binary!(raw_image)
{height, width, num_channels} = image.shape
new_height = div(height, 3)
new_width = div(width, 3)
new_shape = {new_height, new_width, 3}
image = StbImage.resize(image, new_height, new_width)
binary_image = StbImage.to_binary(image, :jpg)
original_image = Kino.Image.new(binary_image, :jpeg)
```

Now we will try to use only ten colors to represent the same picture.

```elixir
x = image |> StbImage.to_nx() |> Nx.reshape({:auto, 3})
k_means = Scholar.Cluster.KMeans.fit(x, num_clusters: 10, num_runs: 10, max_iterations: 200)

new_img = Nx.take(k_means.clusters, k_means.labels)
new_img_reshaped = new_img |> Nx.reshape(new_shape) |> Nx.round() |> Nx.as_type({:u, 8})

binary_new_img = StbImage.from_nx(new_img_reshaped)
new_content = StbImage.to_binary(binary_new_img, :jpg)
Kino.Image.new(new_content, :jpeg)
```

Look that even though we use only ten colors, we can say without any doubt that this is the same image. Let's experiment more deeply. Now we will try 5, 10, 15, 20 and 40 colors and then compare the processed images with the original one.

```elixir
models = for i <- [5, 10, 15, 20, 40], do: Scholar.Cluster.KMeans.fit(x, num_clusters: i)
```

```elixir
new_images = for model <- models, do: Nx.take(model.clusters, model.labels)

results =
  Enum.map_every(new_images, 1, fn x ->
    x
    |> Nx.reshape(new_shape)
    |> Nx.round()
    |> Nx.as_type({:u, 8})
    |> StbImage.from_nx()
    |> StbImage.to_binary(:jpg)
  end)

kino_images = Enum.map_every(results, 1, fn x -> Kino.Image.new(x, :jpeg) end)

grid_content =
  Enum.zip(
    for(i <- [5, 10, 15, 20, 40], do: Kino.Markdown.new("### Number of colors: #{i}")) ++
      [Kino.Markdown.new("### Original Image")],
    kino_images ++ [original_image]
  )

grid_content =
  Enum.reduce(grid_content, [], fn {x, y}, acc ->
    acc ++ [Kino.Layout.grid([x, y], boxed: true)]
  end)

Kino.Layout.grid(grid_content, columns: 2)
```

Look that even with only five colors can recognize the Golden Gate Bridge in the image. On the other hand with only 40 colors we keep almost all details except the sky and water surface. The reason why these two spaces do not map well is that there is a small gradient in changing colors. Pixel clustering is a great way to compress images drastically with small integration in them.

## Clustering Face Images from Fashion-MNIST

The last example is the clustering problem on Fashion-MNIST Dataset. The dataset consists of 60000 images 28 by 28 pixels. They present ten different parts of clothing. Let's dive into this clustering problem.

<!-- livebook:{"break_markdown":true} -->

Before we start, we define the StratifiedSplit module. The module trims input data and splits it, so the number of samples per class is the same for each.

```elixir
defmodule StratifiedSplit do
  defn trim_samples(x, labels, opts \\ []) do
    opts = keyword!(opts, [:num_classes, :samples_per_class])

    num_classes = opts[:num_classes]
    samples_per_class = opts[:samples_per_class]

    membership_mask = Nx.iota({1, num_classes}) == Nx.reshape(labels, {:auto, 1})

    indices =
      membership_mask
      |> Nx.argsort(axis: 0, direction: :desc)
      |> Nx.slice_along_axis(0, samples_per_class, axis: 0)
      |> Nx.flatten()

    {Nx.take(x, indices), Nx.take(labels, indices)}
  end
end
```

Firstly, load the data and cast it into Nx tensors.

```elixir
{data, target} = Scidata.FashionMNIST.download()
{images_binary, images_type, images_shape} = data

{num_samples, _, image_height, image_width} = images_shape

num_classes = 10
samples_per_class = 20

images =
  images_binary
  |> Nx.from_binary(images_type)
  |> Nx.reshape({num_samples, :auto})
  |> Nx.divide(255)

{labels_binary, labels_type, _shape} = target

target =
  labels_binary
  |> Nx.from_binary(labels_type)

{images, target} =
  StratifiedSplit.trim_samples(images, target,
    num_classes: num_classes,
    samples_per_class: samples_per_class
  )

num_images = num_classes * samples_per_class

images = images[[0..(num_images - 1)]]
target = target[[0..(num_images - 1)]]
```

The `ToImage` module will provide us with a function that will cast tensors into Kino.Image objects.

```elixir
defmodule ToImage do
  def tensor_to_image(x, image_height, image_width) do
    x
    |> Nx.reshape({image_height, image_width, 1})
    # 3 channels of png
    |> Nx.broadcast({image_height, image_width, 3})
    |> Nx.multiply(255)
    |> Nx.as_type({:u, 8})
    |> StbImage.from_nx()
    |> StbImage.resize(112, 112)
    |> StbImage.to_binary(:png)
    |> Kino.Image.new(:png)
  end
end
```

Here is one of the images.

```elixir
images[[0, 0..-1//1]] |> ToImage.tensor_to_image(image_height, image_width)
```

We will try some different numbers of clusters and then measure the quality of clustering.

```elixir
nums_clusters = 2..20

models =
  for num_clusters <- nums_clusters,
      do: Scholar.Cluster.KMeans.fit(images, num_clusters: num_clusters)
```

```elixir
inertia_of_models = for model <- models, do: Nx.to_number(model.inertia)
data = [num_clusters: nums_clusters, inertia: inertia_of_models]

Vl.new(width: 600, height: 300, title: "Elbow Plot")
|> Vl.data_from_values(data)
|> Vl.mark(:line)
|> Vl.encode_field(:x, "num_clusters",
  title: "Number of Clusters",
  type: :ordinal,
  axis: [label_angle: 0]
)
|> Vl.encode_field(:y, "inertia",
  title: "Inertia",
  type: :quantitative,
  scale: [domain: [4800, 11500]]
)
```

Look that this time there is no elbow on a plot. We need to use a different method to predict the number of classes. Now we will use *Silhouette Score*. It is a metric that indicates the quality of clustering. The higher score the better clustering. However, we should be aware that Silhouette Score is just a heuristic and not always works.

```elixir
silhouette_scores =
  for {model, num_clusters} <- Enum.zip(models, nums_clusters),
      do:
        Nx.to_number(
          Scholar.Metrics.Clustering.silhouette_score(images, model.labels,
            num_clusters: num_clusters
          )
        )
```

```elixir
data = [num_clusters: nums_clusters, silhouette_scores: silhouette_scores]

Vl.new(width: 600, height: 300, title: "Silhouette score vs Number of Clusters")
|> Vl.data_from_values(data)
|> Vl.layers([
  Vl.new()
  |> Vl.mark(:line)
  |> Vl.encode_field(:x, "num_clusters",
    title: "Number of Clusters",
    type: :ordinal,
    axis: [label_angle: 0]
  )
  |> Vl.encode_field(:y, "silhouette_scores",
    title: "Silhouette score",
    type: :quantitative,
    scale: [domain: [0.088, 0.205]]
  ),
  Vl.new()
  |> Vl.mark(:circle, size: 50, color: :dark_blue)
  |> Vl.encode_field(:x, "num_clusters")
  |> Vl.encode_field(:y, "silhouette_scores", type: :quantitative)
])
```

As we can see, the model with num_clusters equal to 3 has the highest Silhouette Score. Now we will visualize this clusterization.

```elixir
best_num_clusters = 3
best_model = Enum.at(models, best_num_clusters - 2)
```

```elixir
labels = Nx.to_flat_list(best_model.labels)
labels = Enum.zip([labels, 0..(num_images - 1), Nx.to_flat_list(target)])

clustering_map = Map.new(0..(best_num_clusters - 1), &{&1, []})

mapping =
  Enum.reduce(labels, clustering_map, fn {x, idx, ref}, acc ->
    Map.update(acc, x, nil, fn x ->
      x ++
        [
          {ToImage.tensor_to_image(images[[idx, 0..-1//1]], image_height, image_width), ref}
        ]
    end)
  end)

preprocessing =
  Enum.reduce(0..(best_num_clusters - 1), [], fn i, acc ->
    acc ++
      [
        Kino.Layout.grid(
          [Kino.Markdown.new("## Cluster no. #{i}")] ++
            [
              Kino.Layout.grid(
                Enum.reduce(mapping[i], [], fn {image, idx}, acc1 ->
                  acc1 ++
                    [
                      Kino.Layout.grid([
                        Kino.Markdown.new("Reference Cluster no. #{idx}"),
                        image
                      ])
                    ]
                end),
                columns: 5
              )
            ],
          boxed: true
        )
      ]
  end)

Kino.Layout.grid(preprocessing)
```

Ups, doesn't it seem ok? That's because our algorithm for three clusters gathers images by colors rather than shapes. To spot this, let's plot the average image of each cluster.

```elixir
mapping_tensors =
  Enum.reduce(labels, clustering_map, fn {x, idx, _ref}, acc ->
    Map.update(acc, x, nil, fn x ->
      x ++
        [
          images[[idx, 0..-1//1]]
        ]
    end)
  end)

mean_images =
  for i <- 0..(best_num_clusters - 1),
      do:
        Nx.stack(mapping_tensors[i])
        |> Nx.mean(axes: [0])
        |> ToImage.tensor_to_image(image_height, image_width)

Kino.Layout.grid(mean_images, columns: 3)
```

One of the images has a vertical line (something like trousers) while another is almost all white (similar to a jumper) and the last one has lots of dark color. This time Silhouette Score turns out to be not the best indicator. To get better clustering, try to rerun the code with a higher number of clusters.
