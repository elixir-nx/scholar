# K-means tutorial

```elixir
Mix.install(
  [
    {:scholar, github: "elixir-nx/scholar"},
    {:nx, github: "elixir-nx/nx", sparse: "nx", override: true},
    {:exla, github: "elixir-nx/nx", sparse: "exla"},
    {:explorer, "~> 0.2.0"},
    {:stb_image, "~> 0.5.2"},
    {:scidata, "~> 0.1.9"},
    {:jason, "~> 1.2"},
    {:req, "~> 0.3.0"},
    {:kino, github: "livebook-dev/kino", override: true},
    {:vega_lite, "~> 0.1.6"},
    {:kino_vega_lite, "~> 0.1.3"},
    # TODO remove following after new release of finch
    {:nimble_options, "~> 0.5.0", override: true}
  ],
  config: [
    nx: [default_defn_options: [compiler: EXLA]]
  ]
)
```

## Introduction

The main purpose of this livebook is to introduce the KMeans clustering algorithm. We will explore KMeans in three different use cases.

```elixir
alias VegaLite, as: Vl
```

<!-- livebook:{"branch_parent_index":0} -->

## Iris Dataset

The first example we will focus on is the **Iris Dataset**. It is one of the most renowned datasets. It consists of 150 records describing three iris species: *Iris Setosa*, *Iris Virginica*, and *Iris Versicolor*. Our task will be to predict the species of given flowers.

<!-- livebook:{"break_markdown":true} -->

Let's define some utility functions that will help us load data from Explorer Dataframe into Nx tensors.

```elixir
defmodule Iris.Data do
  def df_to_matrix(df) do
    df
    |> Explorer.DataFrame.names()
    |> Enum.map(&Explorer.Series.to_tensor(df[&1]))
    |> Nx.stack(axis: 1)
  end

  def df_to_label_vector(df, name) do
    Explorer.DataFrame.dummies(df, [name])
    |> df_to_matrix()
    |> Nx.argmax(axis: 1)
  end
end
```

Firstly, we load the data, then we split it into Training Data (x) and Target (y) and cast those into Nx tensors.

```elixir
df = Explorer.Datasets.iris()

y = Iris.Data.df_to_label_vector(df, "species")

x =
  df
  |> Explorer.DataFrame.select(["species"], :drop)
  |> Iris.Data.df_to_matrix()
```

### Exploratory Data Analysis

<!-- livebook:{"break_markdown":true} -->

There is an important part of Data Science workflow is called **Exploratory Data Analysis**. EDA helps us understand the data in a better way and suggests some efficient strategies to solve problems. There is no one specific course of action which defines good EDA. It should contain tabular summaries and plots showing relations between features.

<!-- livebook:{"break_markdown":true} -->

iWe start our EDA by finding the mean values of each feature by species.

```elixir
grouped_data = Explorer.DataFrame.group_by(df, ["species"])

grouped_data
|> Explorer.DataFrame.summarise(
  petal_length: [:mean],
  petal_width: [:mean],
  sepal_width: [:mean],
  sepal_length: [:mean]
)
```

We see that `petal_length` and `petal_width` are the most distinguishing features. Let's explore them a little bit more.

```elixir
Vl.new(title: [text: "Histograms of petal_length column by species", offset: 25])
|> Vl.data_from_values(df)
|> Vl.facet(
  [field: "species"],
  Vl.new(width: 200, height: 200)
  |> Vl.mark(:bar)
  |> Vl.encode_field(:x, "petal_length", type: :quantitative, bin: true)
  |> Vl.encode(:y, aggregate: :count, scale: [domain: [0, 55]])
)
```

```elixir
Vl.new(
  width: 300,
  height: 300,
  title: [
    text: "Scatterplot of data samples pojected on plane petal_width x petal_length",
    offset: 25
  ]
)
|> Vl.data_from_values(df)
|> Vl.mark(:circle)
|> Vl.encode_field(:x, "petal_length", type: :quantitative)
|> Vl.encode_field(:y, "petal_width", type: :quantitative)
|> Vl.encode_field(:color, "species")
```

```elixir
Vl.new(
  title: [
    text: "Scatterplot of data samples pojected on plane petal_width x petal_length by species",
    offset: 25
  ]
)
|> Vl.data_from_values(df)
|> Vl.facet(
  [field: "species"],
  Vl.new(width: 200, height: 200)
  |> Vl.mark(:point)
  |> Vl.encode_field(:x, "petal_length", type: :quantitative)
  |> Vl.encode_field(:y, "petal_width", type: :quantitative)
)
```

Now we have a better understanding of the data. Iris species have different petal widths and petal lengths. Iris *Setosa* has the smallest petal, *Versicolor* is medium size and *Virginica* has the biggest petal. We can make sure even further that our analysis is correct and plot the so-called **Elbow plot**. The Elbow plot is a plot which presents Inertia vs the number of clusters. If there is a characteristic elbow on, then we have a strong suggestion about the right number of clusters. Let's train KMeans models for a different number of clusters from range 1 to 11.

```elixir
clusterings = 1..11

models =
  for num_clusters <- clusterings do
    Scholar.Cluster.KMeans.fit(x, num_clusters: num_clusters)
  end

inertias = for model <- models, do: Nx.to_number(model.inertia)
```

```elixir
Vl.new(width: 600, height: 300, title: "Elbow Plot")
|> Vl.data_from_values(num_clusters: clusterings, inertia: inertias)
|> Vl.mark(:line)
|> Vl.encode_field(:x, "num_clusters",
  title: "Number of Clusters",
  type: :ordinal,
  axis: [label_angle: 0]
)
|> Vl.encode_field(:y, "inertia", title: "Inertia", type: :quantitative)
```

As you can see, we have the elbow when the number of clusters equals three. So this value of the parameter seems to be the best.

<!-- livebook:{"break_markdown":true} -->

In order to compare our clustering with the target labels, we need to ensure our clusters are in a matching order.

```elixir
defmodule Iris.Clusters do
  import Nx.Defn

  defn sort_clusters(model) do
    # We sort clusters by the first coordinate
    order = Nx.argsort(model.clusters[[0..-1//1, 0]])
    labels_maping = Nx.argsort(order)

    %{
      model
      | labels: Nx.take(labels_maping, model.labels),
        clusters: Nx.take(model.clusters, order)
    }
  end
end
```

```elixir
best_model = Enum.at(models, 2)
best_model = Iris.Clusters.sort_clusters(best_model)
accuracy = Scholar.Metrics.accuracy(best_model.labels, y)
```

Accuracy is nearly 90%, that's pretty decent! Let's look at our results plotted on one of the previous plots.

```elixir
coords = [
  cluster_petal_length: best_model.clusters[[0..-1//1, 2]] |> Nx.to_flat_list(),
  cluster_petal_width: best_model.clusters[[0..-1//1, 3]] |> Nx.to_flat_list()
]

Vl.new(
  width: 300,
  height: 300,
  title: [
    text:
      "Scatterplot of data samples pojected on plane petal_width x petal_length with calculated centroids",
    offset: 25
  ]
)
|> Vl.layers([
  Vl.new()
  |> Vl.data_from_values(df)
  |> Vl.mark(:circle)
  |> Vl.encode_field(:x, "petal_length", type: :quantitative)
  |> Vl.encode_field(:y, "petal_width", type: :quantitative)
  |> Vl.encode_field(:color, "species"),
  Vl.new()
  |> Vl.data_from_values(coords)
  |> Vl.mark(:circle, color: :green, size: 100)
  |> Vl.encode_field(:x, "cluster_petal_length", type: :quantitative)
  |> Vl.encode_field(:y, "cluster_petal_width", type: :quantitative)
])
```

As we expect ðŸ˜Ž

<!-- livebook:{"branch_parent_index":0} -->

## Clustering of pixel colors

The other interesting use case of KMeans clustering is pixel clustering. This technique replaces all pixels with similar colors (similar in terms of euclidean distance between RGB) with a centroid related to them.

<!-- livebook:{"break_markdown":true} -->

Let us start with loading the referral image.

```elixir
url =
  "https://pix4free.org/assets/library/2021-01-12/originals/san_francisco_california_golden_gate_bridge_water.jpg"

%{body: raw_image} = Req.get!(url)
image = StbImage.read_binary!(raw_image)

{height, width, _num_channels} = image.shape
image = StbImage.resize(image, div(height, 3), div(width, 3))
shape = image.shape

image_kino = image |> StbImage.to_binary(:jpg) |> Kino.Image.new(:jpeg)
```

Now we will try to use only ten colors to represent the same picture.

```elixir
x = image |> StbImage.to_nx() |> Nx.reshape({:auto, 3})
model = Scholar.Cluster.KMeans.fit(x, num_clusters: 10, num_runs: 10, max_iterations: 200)

repainted_x = Nx.take(model.clusters, model.labels)

tensor_to_image = fn x ->
  x
  |> Nx.reshape(shape)
  |> Nx.round()
  |> Nx.as_type({:u, 8})
  |> StbImage.from_nx()
  |> StbImage.to_binary(:jpg)
  |> Kino.Image.new(:jpeg)
end

repainted_x = tensor_to_image.(repainted_x)
```

Look that even though we use only ten colors, we can say without any doubt that this is the same image. Let's experiment more deeply. Now we will try 5, 10, 15, 20 and 40 colors and then compare the processed images with the original one.

```elixir
clusterings = [5, 10, 15, 20, 40]

models =
  for num_clusters <- clusterings do
    Scholar.Cluster.KMeans.fit(x, num_clusters: num_clusters)
  end
```

```elixir
image_boxes =
  for {model, num_clusters} <- Enum.zip(models, clusterings) do
    repainted_x = Nx.take(model.clusters, model.labels)

    image_kino = tensor_to_image.(repainted_x)

    Kino.Layout.grid(
      [Kino.Markdown.new("### Number of colors: #{num_clusters}"), image_kino],
      boxed: true
    )
  end

image_box =
  Kino.Layout.grid(
    [Kino.Markdown.new("### Original image"), image_kino],
    boxed: true
  )

Kino.Layout.grid(image_boxes ++ [image_box], columns: 2)
```

Look that even with only five colors can recognize the Golden Gate Bridge in the image. On the other hand with only 40 colors we keep almost all details except the sky and water surface. The reason why these two spaces do not map well is that there is a small gradient in changing colors. Pixel clustering is a great way to compress images drastically with small integration in them.

<!-- livebook:{"branch_parent_index":0} -->

## Clustering images from Fashion-MNIST

The last example is the clustering problem on the Fashion-MNIST Dataset. The dataset consists of 60000 images 28 by 28 pixels. They present ten different parts of clothing. Let's dive into this clustering problem.

<!-- livebook:{"break_markdown":true} -->

Before we start, we define the StratifiedSplit module. The module trims input data and splits it, so the number of samples per class is the same for each.

```elixir
defmodule StratifiedSplit do
  import Nx.Defn

  defn trim_samples(x, labels, opts \\ []) do
    opts = keyword!(opts, [:num_classes, :samples_per_class])

    num_classes = opts[:num_classes]
    samples_per_class = opts[:samples_per_class]

    membership_mask = Nx.iota({1, num_classes}) == Nx.reshape(labels, {:auto, 1})

    indices =
      membership_mask
      |> Nx.argsort(axis: 0, direction: :desc)
      |> Nx.slice_along_axis(0, samples_per_class, axis: 0)
      |> Nx.flatten()

    {Nx.take(x, indices), Nx.take(labels, indices)}
  end
end
```

Firstly, load the data and cast it into Nx tensors.

```elixir
{image_data, labels_data} = Scidata.FashionMNIST.download()

{images_binary, images_type, images_shape} = image_data
{num_samples, _num_channels = 1, image_height, image_width} = images_shape

images =
  images_binary
  |> Nx.from_binary(images_type)
  |> Nx.reshape({num_samples, :auto})
  |> Nx.divide(255)

{labels_binary, labels_type, _shape} = labels_data
target = Nx.from_binary(labels_binary, labels_type)

num_classes = 10
samples_per_class = 20

{images, target} =
  StratifiedSplit.trim_samples(images, target,
    num_classes: num_classes,
    samples_per_class: samples_per_class
  )

num_images = num_classes * samples_per_class
```

Let's also define a function that will visualize an image in the tensor format for us.

```elixir
tensor_to_kino = fn x ->
  x
  |> Nx.reshape({image_height, image_width, 1})
  # Replicate the value into 3 channels for PNG
  |> Nx.broadcast({image_height, image_width, 3})
  |> Nx.multiply(255)
  |> Nx.as_type({:u, 8})
  |> StbImage.from_nx()
  |> StbImage.resize(112, 112)
  |> StbImage.to_binary(:png)
  |> Kino.Image.new(:png)
end
```

Here is one of the images.

```elixir
tensor_to_kino.(images[0])
```

We will try some different numbers of clusters and then measure the quality of clustering.

```elixir
nums_clusters = 2..20

models =
  for num_clusters <- 2..20 do
    Scholar.Cluster.KMeans.fit(images, num_clusters: num_clusters)
  end
```

```elixir
data = [
  num_clusters: nums_clusters,
  inertia: for(model <- models, do: Nx.to_number(model.inertia))
]

Vl.new(width: 600, height: 300, title: "Elbow Plot")
|> Vl.data_from_values(data)
|> Vl.mark(:line)
|> Vl.encode_field(:x, "num_clusters",
  title: "Number of Clusters",
  type: :ordinal,
  axis: [label_angle: 0]
)
|> Vl.encode_field(:y, "inertia",
  title: "Inertia",
  type: :quantitative,
  scale: [domain: [4800, 11500]]
)
```

Look that this time there is no elbow on a plot. We need to use a different method to predict the number of classes. Now we will use *Silhouette Score*. It is a metric that indicates the quality of clustering. The higher score the better clustering. However, we should be aware that Silhouette Score is just a heuristic and not always works.

```elixir
silhouette_scores =
  for {model, num_clusters} <- Enum.zip(models, nums_clusters) do
    Scholar.Metrics.Clustering.silhouette_score(images, model.labels, num_clusters: num_clusters)
    |> Nx.to_number()
  end
```

```elixir
data = [num_clusters: nums_clusters, silhouette_scores: silhouette_scores]

Vl.new(width: 600, height: 300, title: "Silhouette score vs Number of Clusters")
|> Vl.data_from_values(data)
|> Vl.layers([
  Vl.new()
  |> Vl.mark(:line)
  |> Vl.encode_field(:x, "num_clusters",
    title: "Number of Clusters",
    type: :ordinal,
    axis: [label_angle: 0]
  )
  |> Vl.encode_field(:y, "silhouette_scores",
    title: "Silhouette score",
    type: :quantitative,
    scale: [domain: [0.088, 0.205]]
  ),
  Vl.new()
  |> Vl.mark(:circle, size: 50, color: :dark_blue)
  |> Vl.encode_field(:x, "num_clusters")
  |> Vl.encode_field(:y, "silhouette_scores", type: :quantitative)
])
```

As we can see, the model with num_clusters equal to 3 has the highest Silhouette Score. Now we will visualize this clusterization.

```elixir
best_num_clusters = 3
best_model = Enum.at(models, 1)
```

```elixir
predicted_cluster_with_indices =
  best_model.labels
  |> Nx.to_flat_list()
  |> Enum.with_index()
  |> Enum.group_by(&elem(&1, 0), &elem(&1, 1))

for cluster <- 0..(best_num_clusters - 1) do
  indices = predicted_cluster_with_indices[cluster]

  boxes =
    for index <- indices do
      original_cluster = Nx.to_number(target[index])

      Kino.Layout.grid([
        Kino.Markdown.new("Original cluster: #{original_cluster}"),
        tensor_to_kino.(images[index])
      ])
    end

  Kino.Layout.grid(
    [
      Kino.Markdown.new("## Cluster #{cluster}"),
      Kino.Layout.grid(boxes, columns: 5)
    ],
    boxed: true
  )
end
|> Kino.Layout.grid()
```

Oops, it doesn't look right! That's because our algorithm for three clusters gathers images by colors rather than shapes. To spot this, let's plot the average image of each cluster.

```elixir
for cluster <- 0..(best_num_clusters - 1) do
  indices = predicted_cluster_with_indices[cluster]

  mean_image =
    indices
    |> Enum.map(&images[&1])
    |> Nx.stack()
    |> Nx.mean(axes: [0])

  tensor_to_kino.(mean_image)
end
|> Kino.Layout.grid(columns: 3)
```

One of the images has a vertical line (something like trousers) while another is almost all white (similar to a jumper) and the last one has lots of dark color. This time Silhouette Score turns out to be not the best indicator. To get better clustering, try to rerun the code with a higher number of clusters.
